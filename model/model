{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/jiangyuxin/anaconda3/envs/bert_base/lib/python3.9/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/export/home/jiangyuxin/anaconda3/envs/bert_base/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score,confusion_matrix,matthews_corrcoef,make_scorer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import esm\n",
    "import xgboost as xgb\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  \n",
    "np.random.seed(42) \n",
    "torch.manual_seed(42)  \n",
    "torch.cuda.manual_seed_all(42)  \n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = '/path/to/your/fireprot_data.json' \n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "predata = pd.DataFrame(data)\n",
    "y_table = predata['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireprot_features = np.load(\"path/to/your/fireprot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "mcc_scores = []\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 300,\n",
    "    'scale_pos_weight': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'random_state': 42\n",
    "}\n",
    "num_features = 4400\n",
    "\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(fireprot_features, y_table)):\n",
    "    print(f\"\\nTraining fold {fold+1}...\")\n",
    "    X_train, X_val = fireprot_features[train_idx], fireprot_features[val_idx]\n",
    "    y_train, y_val = y_table[train_idx], y_table[val_idx]\n",
    "    ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model_xgb = xgb.XGBClassifier(**params)\n",
    "    model_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "    feature_importances = model_xgb.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importances)[::-1] \n",
    "    selected_features = sorted_idx[:num_features]\n",
    "    X_train_selected = X_train_resampled[:, selected_features]\n",
    "    X_val_selected = X_val[:, selected_features]  \n",
    "    model_xgb.fit(X_train_selected, y_train_resampled)\n",
    "    y_pred = model_xgb.predict(X_val_selected)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  \n",
    "    y_pred_prob = model_xgb.predict_proba(X_val_selected)[:, 1]\n",
    "    accuracy = accuracy_score(y_val, y_pred_binary)\n",
    "    auc = roc_auc_score(y_val, y_pred_prob)\n",
    "    mcc = matthews_corrcoef(y_val, y_pred_binary)\n",
    "    f1 = f1_score(y_val, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred_binary).ravel()\n",
    "    sensitivity = tp / (tp + fn)  \n",
    "    specificity = tn / (tn + fp)  \n",
    "    accuracies.append(accuracy)\n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(auc)\n",
    "    mcc_scores.append(mcc)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Accuracy: {accuracy:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, AUC: {auc:.4f}, MCC: {mcc:.4f}, F1 Score: {f1:.4f}\")\n",
    "    model_xgb.save_model(f'path/to/save/{fold+1}_model.json')\n",
    "\n",
    "print(\"\\nAverage results over 5 folds:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
    "print(f\"Average AUC: {np.mean(auc_scores):.4f}\")\n",
    "print(f\"Average MCC: {np.mean(mcc_scores):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_auc = np.mean(auc_scores)\n",
    "avg_mcc = np.mean(mcc_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_sensitivity = np.mean(sensitivities)\n",
    "avg_specificity = np.mean(specificities)\n",
    "\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_auc = np.std(auc_scores)\n",
    "std_mcc = np.std(mcc_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "std_sensitivity = np.std(sensitivities)\n",
    "std_specificity = np.std(specificities)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average AUC: {avg_auc:.4f} ± {std_auc:.4f}\")\n",
    "print(f\"Average MCC: {avg_mcc:.4f} ± {std_mcc:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Average Sensitivity: {avg_sensitivity:.4f} ± {std_sensitivity:.4f}\")\n",
    "print(f\"Average Specificity: {avg_specificity:.4f} ± {std_specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = '/path/to/your/calb_data.json' \n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "predata = pd.DataFrame(data)\n",
    "y_table = predata['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calb_features = np.load(\"path/to/your/calb_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_accuracies = []\n",
    "finetune_f1_scores = []\n",
    "finetune_auc_scores = []\n",
    "finetune_mcc_scores = []\n",
    "finetune_sensitivities = []\n",
    "finetune_specificities = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(calb_features, y_table)):\n",
    "    print(f\"\\nFine-tuning fold {fold+1}...\")\n",
    "    model_xgb = xgb.Booster()\n",
    "    model_xgb.load_model('path/to/your/pretrain_model')\n",
    "    X_train_calb, X_val_calb =calb_features[train_idx], calb_features[val_idx]\n",
    "    y_train_calb, y_val_calb = y_table[train_idx],  y_table[val_idx]\n",
    "    ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled_calb, y_train_resampled_calb = ros.fit_resample(X_train_calb, y_train_calb)\n",
    "    dtrain_calb = xgb.DMatrix(X_train_resampled_calb, label=y_train_resampled_calb)\n",
    "    dval_calb = xgb.DMatrix(X_val_calb, label=y_val_calb)\n",
    "    finetune_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 80,\n",
    "        'learning_rate': 0.04,\n",
    "        'n_estimators': 300,\n",
    "        'scale_pos_weight': 2,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'random_state': 45\n",
    "        \n",
    "    }\n",
    "    model_xgb_finetuned = xgb.train(finetune_params, dtrain_calb, num_boost_round=300, xgb_model=model_xgb)\n",
    "    \n",
    "    y_pred_calb = model_xgb_finetuned.predict(dval_calb)\n",
    "    y_pred_binary_calb = (y_pred_calb > 0.5).astype(int)\n",
    "\n",
    "    accuracy_calb = accuracy_score(y_val_calb, y_pred_binary_calb)\n",
    "    auc_calb = roc_auc_score(y_val_calb, y_pred_binary_calb)\n",
    "    mcc_calb = matthews_corrcoef(y_val_calb, y_pred_binary_calb)\n",
    "    f1_calb = f1_score(y_val_calb, y_pred_binary_calb)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_calb, y_pred_binary_calb).ravel()\n",
    "    sensitivity_calb = tp / (tp + fn)\n",
    "    specificity_calb = tn / (tn + fp)\n",
    "    \n",
    "    finetune_accuracies.append(accuracy_calb)\n",
    "    finetune_auc_scores.append(auc_calb)\n",
    "    finetune_mcc_scores.append(mcc_calb)\n",
    "    finetune_f1_scores.append(f1_calb)\n",
    "    finetune_sensitivities.append(sensitivity_calb)\n",
    "    finetune_specificities.append(specificity_calb)\n",
    "    \n",
    "    print(f\"Fine-tune Fold {fold+1} - Accuracy: {accuracy_calb:.4f}, Sensitivity: {sensitivity_calb:.4f}, Specificity: {specificity_calb:.4f}, AUC: {auc_calb:.4f}, MCC: {mcc_calb:.4f}, F1 Score: {f1_calb:.4f}\")\n",
    "\n",
    "avg_accuracy = np.mean(finetune_accuracies)\n",
    "std_accuracy = np.std(finetune_accuracies)\n",
    "avg_auc = np.mean(finetune_auc_scores)\n",
    "std_auc = np.std(finetune_auc_scores)\n",
    "avg_mcc = np.mean(finetune_mcc_scores)\n",
    "std_mcc = np.std(finetune_mcc_scores)\n",
    "avg_f1 = np.mean(finetune_f1_scores)\n",
    "std_f1 = np.std(finetune_f1_scores)\n",
    "avg_sensitivity = np.mean(finetune_sensitivities)\n",
    "std_sensitivity = np.std(finetune_sensitivities)\n",
    "avg_specificity = np.mean(finetune_specificities)\n",
    "std_specificity = np.std(finetune_specificities)\n",
    "\n",
    "print(\"\\nAverage fine-tune results over 5 folds:\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Average Sensitivity: {avg_sensitivity:.4f} ± {std_sensitivity:.4f}\")\n",
    "print(f\"Average Specificity: {avg_specificity:.4f} ± {std_specificity:.4f}\")\n",
    "print(f\"Average AUC: {avg_auc:.4f} ± {std_auc:.4f}\")\n",
    "print(f\"Average MCC: {avg_mcc:.4f} ± {std_mcc:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f} ± {std_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = '/path/to/your/myoglobin_data.json' \n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "predata = pd.DataFrame(data)\n",
    "y_table = predata['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myoglobin_features = np.load(\"path/to/your/myoglobin_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=45)\n",
    "finetune_accuracies = []\n",
    "finetune_f1_scores = []\n",
    "finetune_auc_scores = []\n",
    "finetune_mcc_scores = []\n",
    "finetune_sensitivities = []\n",
    "finetune_specificities = []\n",
    "\n",
    "num_features = 4400\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(myoglobin_features, y_table)):\n",
    "    print(f\"\\nFine-tuning fold {fold+1}...\")\n",
    "    X_train_myoglobin, X_val_myoglobin =myoglobin_features[train_idx], myoglobin_features[val_idx]\n",
    "    y_train_myoglobin, y_val_myoglobin = y_table[train_idx], y_table[val_idx]\n",
    "   \n",
    "    ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled_myoglobin, y_train_resampled_myoglobin = ros.fit_resample(X_train_myoglobin, y_train_myoglobin)\n",
    "    \n",
    "    model_xgb = xgb.XGBClassifier()\n",
    "    model_xgb.load_model(f'path/to/your/pretrain_model') \n",
    "    feature_importances = model_xgb.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importances)[::-1] \n",
    "    selected_idx = sorted_idx[:num_features]\n",
    "\n",
    "    X_train_selected = X_train_resampled_myoglobin[:, selected_idx]\n",
    "    X_val_selected = X_val_myoglobin[:, selected_idx]\n",
    "    dtrain_myoglobin = xgb.DMatrix(X_train_selected, label=y_train_resampled_myoglobin)\n",
    "    dval_myoglobin = xgb.DMatrix(X_val_selected, label=y_val_myoglobin)\n",
    "\n",
    "    finetune_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 30,\n",
    "        'learning_rate': 0.06,\n",
    "        'n_estimators': 300,\n",
    "        'scale_pos_weight': 1.5,\n",
    "        'subsample': 0.85,\n",
    "        'colsample_bytree': 0.85,\n",
    "        'random_state': 45\n",
    "        \n",
    "    }\n",
    "    \n",
    "    model_xgb_finetuned = xgb.train(\n",
    "        finetune_params,\n",
    "        dtrain_myoglobin,\n",
    "        num_boost_round=300,\n",
    "        xgb_model=model_xgb.get_booster()  )\n",
    "    y_pred_myoglobin = model_xgb_finetuned.predict(dval_myoglobin)\n",
    "    y_pred_binary_myoglobin = (y_pred_myoglobin > 0.5).astype(int)\n",
    "\n",
    "    accuracy_myoglobin = accuracy_score(y_val_myoglobin, y_pred_binary_myoglobin)\n",
    "    auc_myoglobin = roc_auc_score(y_val_myoglobin, y_pred_binary_myoglobin)\n",
    "    mcc_myoglobin = matthews_corrcoef(y_val_myoglobin, y_pred_binary_myoglobin)\n",
    "    f1_myoglobin = f1_score(y_val_myoglobin, y_pred_binary_myoglobin)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val_myoglobin, y_pred_binary_myoglobin).ravel()\n",
    "    sensitivity_myoglobin = tp / (tp + fn)\n",
    "    specificity_myoglobin = tn / (tn + fp)\n",
    "    \n",
    "    finetune_accuracies.append(accuracy_myoglobin)\n",
    "    finetune_auc_scores.append(auc_myoglobin)\n",
    "    finetune_mcc_scores.append(mcc_myoglobin)\n",
    "    finetune_f1_scores.append(f1_myoglobin)\n",
    "    finetune_sensitivities.append(sensitivity_myoglobin)\n",
    "    finetune_specificities.append(specificity_myoglobin)\n",
    "    \n",
    "    print(f\"Fine-tune Fold {fold+1} - Accuracy: {accuracy_myoglobin:.4f}, Sensitivity: {sensitivity_myoglobin:.4f}, Specificity: {specificity_myoglobin:.4f}, AUC: {auc_myoglobin:.4f}, MCC: {mcc_myoglobin:.4f}, F1 Score: {f1_myoglobin:.4f}\")\n",
    "    \n",
    "\n",
    "print(\"\\nAverage fine-tune results over 5 folds:\")\n",
    "print(f\"Average Accuracy: {np.mean(finetune_accuracies):.4f}\")\n",
    "print(f\"Average Sensitivity: {np.mean(finetune_sensitivities):.4f}\")\n",
    "print(f\"Average Specificity: {np.mean(finetune_specificities):.4f}\")\n",
    "print(f\"Average AUC: {np.mean(finetune_auc_scores):.4f}\")\n",
    "print(f\"Average MCC: {np.mean(finetune_mcc_scores):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(finetune_f1_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
